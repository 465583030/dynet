{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train an LSTM model over a large vocabulary.\n",
    "\n",
    "We do not care so much about the perplexity / probability as much as we care about the representation itself, but we want to (pre)train it in an unsupervised way, so we will use the corpus (previous words) as our guiding principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we assume that we have the pycnn module in your path.\n",
    "# we also assume that LD_LIBRARY_PATH includes a pointer to where libcnn_shared.so is.\n",
    "from pycnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An LSTM/RNN overview:\n",
    "\n",
    "An (1-layer) RNN can be thought of as a sequence of cells, $h_1,...,h_k$, where $h_i$ indicates the time dimenstion. \n",
    "\n",
    "Each cell $h_i$ has an input $x_i$ and an output $r_i$. In addition to $x_i$, cell $h_i$ receives as input also $r_{i-1}$.\n",
    "\n",
    "In a deep (multi-layer) RNN, we don't have a sequence, but a grid. That is we have several layers of sequences:\n",
    "\n",
    "* $h_1^3,...,h_k^3$ \n",
    "* $h_1^2,...,h_k^2$ \n",
    "* $h_1^1,...h_k^1$, \n",
    "\n",
    "Let $r_i^j$ be the output of cell $h_i^j$. Then:\n",
    "\n",
    "The input to $h_i^1$ is $x_i$ and $r_{i-1}^1$.\n",
    "\n",
    "The input to $h_i^2$ is $r_i^1$ and $r_{i-1}^2$,\n",
    "and so on.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LSTM (RNN) Interface\n",
    "\n",
    "RNN / LSTM / GRU follow the same interface. We have a \"builder\" which is in charge of creating definining the parameters for the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "NUM_LAYERS=2\n",
    "INPUT_DIM=50\n",
    "HIDDEN_DIM=10\n",
    "builder = LSTMBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "# or:\n",
    "# builder = SimpleRNNBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we create the builder, it adds the internal RNN parameters to the `model`.\n",
    "We do not need to care about them, but they will be optimized together with the rest of the network's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = builder.initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = vecInput(INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1=s0.add_input(x1)\n",
    "y1 = s1.output()\n",
    "# here, we add x1 to the RNN, and the output we get from the top is y (a HIDEN_DIM-dim vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.npvalue().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2=s1.add_input(x1) # we can add another input\n",
    "y2=s2.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our LSTM/RNN was one layer deep, y2 would be equal to the hidden state. However, since it is 2 layers deep, y2 is only the hidden state (= output) of the last layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to want access to the all the hidden state (the output of both the first and the last layers), we could use the `.h()` method, which returns a list of expressions, one for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exprssion 54/0, exprssion 66/0)\n"
     ]
    }
   ],
   "source": [
    "print s2.h()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same interface that we saw until now for the LSTM, holds also for the Simple RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all layers: (exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "# create a simple rnn builder\n",
    "rnnbuilder=SimpleRNNBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "\n",
    "# initialize a new graph, and a new sequence\n",
    "rs0 = rnnbuilder.initial_state()\n",
    "\n",
    "# add inputs\n",
    "rs1 = rs0.add_input(x1)\n",
    "ry1 = rs1.output()\n",
    "print \"all layers:\", s1.h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exprssion 28/0, exprssion 38/0, exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "print s1.s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, when calling `.add_input(x)` on an `RNNState` what happens is that the state creates a new RNN/LSTM column, passing it: \n",
    "1. the state of the current RNN column\n",
    "2. the input `x`\n",
    "\n",
    "The state is then returned, and we can call it's `output()` method to get the output `y`, which is the output at the top of the column. We can access the outputs of all the layers (not only the last one) using the `.h()` method of the state.\n",
    "\n",
    "**`.s()`** The internal state of the RNN may be more involved than just the outputs $h$. This is the case for the LSTM, that keeps an extra \"memory\" cell, that is used when calculating $h$, and which is also passed to the next column.  To access the entire hidden state, we use the `.s()` method. \n",
    "\n",
    "The output of `.s()` differs by the type of RNN being used. For the simple-RNN, it is the same as `.h()`. For the LSTM, it is more involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN h: (exprssion 74/0, exprssion 76/0)\n",
      "RNN s: (exprssion 74/0, exprssion 76/0)\n",
      "LSTM h: (exprssion 32/0, exprssion 42/0)\n",
      "LSTM s: (exprssion 28/0, exprssion 38/0, exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "rnn_h  = rs1.h()\n",
    "rnn_s  = rs1.s()\n",
    "print \"RNN h:\", rnn_h\n",
    "print \"RNN s:\", rnn_s\n",
    "\n",
    "\n",
    "lstm_h = s1.h()\n",
    "lstm_s = s1.s()\n",
    "print \"LSTM h:\", lstm_h\n",
    "print \"LSTM s:\", lstm_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the LSTM has two extra state expressions (one for each hidden layer) before the outputs h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra options in the RNN/LSTM interface\n",
    "\n",
    "**Stack LSTM** The RNN's are shaped as a stack: we can remove the top and continue from the previous state.\n",
    "This is done either by remembering the previous state and continuing it with a new `.add_input()`, or using\n",
    "we can access the previous state of a given state using the `.prev()` method of state.\n",
    "\n",
    "**Initializing a new sequence with a given state** When we call `builder.initial_state()`, we are assuming the state has random /0 initialization. If we want, we can specify a list of expressions that will serve as the initial state. The expected format is the same as the results of a call to `.final_s()`. TODO: this is not supported yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2=s1.add_input(x1)\n",
    "s3=s2.add_input(x1)\n",
    "s4=s3.add_input(x1)\n",
    "\n",
    "# let's continue s3 with a new input.\n",
    "s5=s3.add_input(x1)\n",
    "\n",
    "# we now have two different sequences:\n",
    "# s0,s1,s2,s3,s4\n",
    "# s0,s1,s2,s3,s5\n",
    "# the two sequences share parameters.\n",
    "\n",
    "assert(s5.prev() == s3)\n",
    "assert(s4.prev() == s3)\n",
    "\n",
    "s6=s3.prev().add_input(x1)\n",
    "# we now have an additional sequence:\n",
    "# s0,s1,s2,s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exprssion 184/0, exprssion 196/0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6.h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exprssion 180/0, exprssion 192/0, exprssion 184/0, exprssion 196/0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6.s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Charecter-level LSTM\n",
    "\n",
    "Now that we know the basics of RNNs, let's build a character-level LSTM language-model.\n",
    "We have a sequence LSTM that, at each step, gets as input a character, and needs to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "import sys\n",
    "\n",
    "LAYERS = 2\n",
    "INPUT_DIM = 50 \n",
    "HIDDEN_DIM = 50  \n",
    "\n",
    "characters = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "characters.append(\"<EOS>\")\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "\n",
    "srnn = SimpleRNNBuilder(LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "lstm = LSTMBuilder(LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "\n",
    "model.add_lookup_parameters(\"lookup\", (VOCAB_SIZE, INPUT_DIM))\n",
    "model.add_parameters(\"R\", (VOCAB_SIZE, HIDDEN_DIM))\n",
    "model.add_parameters(\"bias\", (VOCAB_SIZE))\n",
    "\n",
    "# return compute loss of RNN for one sentence\n",
    "def do_one_sentence(rnn, sentence):\n",
    "    # setup the sentence\n",
    "    renew_cg()\n",
    "    s0 = rnn.initial_state()\n",
    "    \n",
    "    \n",
    "    R = parameter(model[\"R\"])\n",
    "    bias = parameter(model[\"bias\"])\n",
    "    lookup = model[\"lookup\"]\n",
    "    sentence = [\"<EOS>\"] + list(sentence) + [\"<EOS>\"]\n",
    "    sentence = [char2int[c] for c in sentence]\n",
    "    s = s0\n",
    "    loss = []\n",
    "    for char,next_char in zip(sentence,sentence[1:]):\n",
    "        s = s.add_input(lookup[char])\n",
    "        probs = softmax(R*s.output() + bias)\n",
    "        loss.append( -log(pick(probs,next_char)) )\n",
    "    loss = esum(loss)\n",
    "    return loss\n",
    " \n",
    "\n",
    "# generate from model:\n",
    "def generate(rnn):\n",
    "    def sample(probs):\n",
    "        rnd = random.random()\n",
    "        for i,p in enumerate(probs):\n",
    "            rnd -= p\n",
    "            if rnd <= 0: break\n",
    "        return i\n",
    "    \n",
    "    # setup the sentence\n",
    "    renew_cg()\n",
    "    s0 = rnn.initial_state()\n",
    "    \n",
    "    R = parameter(model[\"R\"])\n",
    "    bias = parameter(model[\"bias\"])\n",
    "    lookup = model[\"lookup\"]\n",
    "    \n",
    "    s = s0.add_input(lookup[char2int[\"<EOS>\"]])\n",
    "    out=[]\n",
    "    while True:\n",
    "        probs = softmax(R*s.output() + bias)\n",
    "        probs = probs.vec_value()\n",
    "        next_char = sample(probs)\n",
    "        out.append(int2char[next_char])\n",
    "        if out[-1] == \"<EOS>\": break\n",
    "        s = s.add_input(lookup[next_char])\n",
    "    return \"\".join(out[:-1]) # strip the <EOS>\n",
    "        \n",
    "\n",
    "# train, and generate every 5 samples\n",
    "def train(rnn, sentence):\n",
    "    trainer = SimpleSGDTrainer(model)\n",
    "    for i in xrange(200):\n",
    "        loss = do_one_sentence(rnn, sentence)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "        if i % 5 == 0: \n",
    "            print loss_value,\n",
    "            print generate(rnn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "1. We pass the same rnn-builder to `do_one_sentence` over and over again.\n",
    "We must re-use the same rnn-builder, as this is where the shared parameters are kept.\n",
    "2. We `renew_cg()` before each sentence -- because we want to have a new graph (new network) for this sentence.\n",
    "The parameters will be shared through the model and the shared rnn-builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.679000854 lmt nx ygtflbjxpoq lwy f\n",
      "92.4982833862 afjvta ltvopebstkfdo rlo yqnopb  ifpqbzi\n",
      "61.3959312439 aavleiq po  rvtzeakqyg zur\n",
      "37.0580444336 vnlbclj fjo j mamlndfe  dixnjhgdtof bdzhe ddvyuwa ohryltop fvek cemouaa dcg ndeilci  cxgphmzthauhxzcl\n",
      "19.9309463501 iwomtno iwv nwe\n",
      "7.24577760696 a quicknbrown  vx tuxpcy ouxr she hazy dog\n",
      "2.65018558502 a quick brown fox jumped over tue lazy dog\n",
      "0.954704046249 a quick brown fox jhmped over the lazy dog\n",
      "0.626812160015 a quick brown fox jumped over the lazy dog\n",
      "0.466860800982 a quick brown fox jumped over the lazy dog\n",
      "0.37179967761 a quick brown fox jumped over the lazy dog\n",
      "0.308676809072 a quick brown fox jumped over the lazy dog\n",
      "0.263797819614 a quick brown fox jumped over the lazy dog\n",
      "0.230166554451 a quick brown fox jumped over the lazx dog\n",
      "0.204109430313 a quick brown fox jumped over the lazy dog\n",
      "0.183262810111 a nuick browk fox jumped over the lazy dog\n",
      "0.166249394417 a quick brown fox jumped over the lazy dog\n",
      "0.152071535587 a quick brown fox jumped over whe lazy dog\n",
      "0.140101358294 a quick brown fox jumped over the lazy dog\n",
      "0.129877090454 a quick brown fox jumped over the lazy dog\n",
      "0.121072113514 a quick brown fox jumped over the lazy dog\n",
      "0.113252848387 a quick brown fox jumped over the lazy dog\n",
      "0.106449194252 a quick brown fox jumped over the lazy dog\n",
      "0.100415848196 a quick brown fox jumped over the lazy dog\n",
      "0.09498013556 a quick brown fox jumped over the lazy dog\n",
      "0.0900921970606 a quick brown fox jumped over the lazy dog\n",
      "0.0856867656112 a quick brown fox jumped over the lazy dog\n",
      "0.0817062109709 a quick brown fox jumped over the lazy dog\n",
      "0.0780855119228 a quick brown fox jumped over the lazy dog\n",
      "0.0747060477734 a quick brown fox jumped over the lazy dog\n",
      "0.0716441199183 a quick brown fox jumped over the lazy dog\n",
      "0.0688194260001 a quick brown fox jumped over the lazy dog\n",
      "0.0662013664842 a quick brown fox jumped over the lazy dog\n",
      "0.0637593045831 a quick brown fox jumped over the lazy dog\n",
      "0.0614740736783 a quick brown fox jumped over the lazy dog\n",
      "0.0594449453056 a quick brown fox jumped over the lazy dog\n",
      "0.0574542097747 a quick brown fox jumped over the lazy dog\n",
      "0.0555782169104 a quick brown fox jumped over the lazy dog\n",
      "0.0538321807981 a quick brown fox jumped over the lazy dog\n",
      "0.0522314347327 a quick brown fox jumped over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "sentence = \"a quick brown fox jumped over the lazy dog\"\n",
    "train(srnn, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.691223145  uvybot firnqqci \n",
      "130.66217041  nud  s ddco  e u  sqo ryastfig scoxoupa se  mz jmxr  v\n",
      "126.464065552 uuipfaa gyoe pmftgnidnvonf  uyddorehj zxbuatudorecdaneoo oepvq uox\n",
      "118.422286987 s l whurp yypde beyn  ex kavk  x  uzdlboxc tuq ac aupztide rdmfua qe e wm jxu\n",
      "105.712097168 e ck  ohelfl e akmfer oewe gp os\n",
      "90.3664779663 gzh dofuth lxjuaz thke\n",
      "77.7215118408 a eckn vv\n",
      "64.3503112793 jr vrof\n",
      "55.7599029541 d zcsn ver fe zezz doj dor em ed ama xuei ob\n",
      "47.3434677124 gcz bbovrw vunmpjd ofg\n",
      "39.2717132568  auil bkbgor ffhg tde abgea oirn ffxgz die berr tref efhe hde oei \n",
      "29.5673542023 uqyk qvog tvm for  oxx jtme dxgk tve laue doy qfx dzz do rh thl dze do ex uuee don frx jamm dur eohn fom pdo jhe duz qzg qwor hote l oe joy jox fmqme doch vinn tte ta luzc do\n",
      "23.5196590424 \n",
      "17.6167182922 k iock nogr the lzz upiek vohe ttea loa pdogw theplddoy bdor joa muuped over the lazy doger ohen ohe amzy dor\n",
      "13.1281785965 b dugckk howr fo\n",
      "8.73806285858 p quxpd over the laza doo\n",
      "6.34239006042 a quik bron fox jumped b\n",
      "4.15951299667 ca quick brown fox jumpedd over the lazy dog\n",
      "2.31204366684 pa quick brown fox jumped over the lazy dog\n",
      "1.6212117672 b dog\n",
      "1.25511050224 a quick brown fox jumped over the laay dog\n",
      "1.01962459087 a quick brown fox jumped over the lazy dog\n",
      "0.856129348278 y quick brown fox jumped over the lazy dog\n",
      "0.736417710781 a quick brown fox jumped over the lazy dog\n",
      "0.645215630531 ua quikk brown fox jumped over the lazy dog\n",
      "0.573442876339 a quick brown fox jumped over the lazy dog\n",
      "0.515612900257 a quick brown fox jumped over the lazy dog\n",
      "0.468045383692 a quick brown fox jumped over the lazy dog\n",
      "0.428334087133 a quick brown fox jumped over the lazy dog\n",
      "0.394624918699 a quick brown fox jumped over the lazy dog\n",
      "0.365713119507 a quick brown fox jumped over the lazy dog\n",
      "0.340574681759 a quick brown fox jumped over tee lazy dog\n",
      "0.318626344204 a quick brown fox jumped over the lazy dog\n",
      "0.299313008785 a quick brown fox jumped over the lazy dog\n",
      "0.282055020332 aa quick brown fox jumped over the lazy dog\n",
      "0.266678541899 a quick brown fox jumped over the lazy dog\n",
      "0.252810955048 a quick brown fox jumped over the lazy dog\n",
      "0.240284785628 a quick brown fox jumped over the lazy dog\n",
      "0.228963255882 a quick brown fox jumped over the lazy dog\n",
      "0.218599379063 a quick brown fox jumped over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "sentence = \"a quick brown fox jumped over the lazy dog\"\n",
    "train(lstm, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seem to learn the sentence quite well.\n",
    "\n",
    "Somewhat surprisingly, the Simple-RNN model learn quicker than the LSTM!\n",
    "\n",
    "How can that be?\n",
    "\n",
    "The answer is that we are cheating a bit. The sentence we are trying to learn\n",
    "has each letter exactly once. This means a simple bigram model can memorize\n",
    "it very well.\n",
    "\n",
    "Try it out with more complex sequences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.674530029 a quick brown fox jumped over the lazy dog\n",
      "105.89151001 a quick brown fox jumped over the lazy dog\n",
      "47.5085983276 a quick browitleh aheclazy dog\n",
      "14.6825256348 thellazy dog\n",
      "2.44217705727 the ere makqne mn thi ste\n",
      "0.339166790247 thele pretzels are making me thirsty\n",
      "0.185528486967 these pretzels are making me thirsty\n",
      "0.136738568544 these mretsels are making me thirsty\n",
      "0.109439112246 these pretzels are making me thirsty\n",
      "0.0916935577989 these pretzels are making me thirsty\n",
      "0.0791544318199 these pretzels are making me thirsty\n",
      "0.0697760358453 these pretzels are making me thirsty\n",
      "0.0624843500555 these pretzels are making me thirsty\n",
      "0.0566432401538 these pretzels are making me thirsty\n",
      "0.0518313497305 these pretzels are making me thirsty\n",
      "0.0478418208659 these pretzels are making me thirsty\n",
      "0.0444259755313 these pretzels are making me thirsty\n",
      "0.0414918512106 these pretzels are making me thirsty\n",
      "0.0389476977289 these pretzels are making me thirsty\n",
      "0.0366978682578 these pretzels are making me thirsty\n",
      "0.0347270295024 these pretzels are making me thirsty\n",
      "0.0329472795129 these pretzels are making me thirsty\n",
      "0.0313814878464 these pretzels are making me thirsty\n",
      "0.0299570858479 these pretzels are making me thirsty\n",
      "0.0286129526794 these pretzels are making me thirsty\n",
      "0.0274254083633 these pretzels are making me thirsty\n",
      "0.0263181217015 these pretzels are making me thirsty\n",
      "0.0253330375999 these pretzels are making me thirsty\n",
      "0.0244014579803 these pretzels are making me thirsty\n",
      "0.0235347989947 these pretzels are making me thirsty\n",
      "0.0227559711784 these pretzels are making me thirsty\n",
      "0.0219390057027 these pretzels are making me thirsty\n",
      "0.0212938319892 these pretzels are making me thirsty\n",
      "0.0206219516695 these pretzels are making me thirsty\n",
      "0.0200188029557 these pretzels are making me thirsty\n",
      "0.0194500312209 these pretzels are making me thirsty\n",
      "0.0189003441483 these pretzels are making me thirsty\n",
      "0.0183964911848 these pretzels are making me thirsty\n",
      "0.0178849939257 these pretzels are making me thirsty\n",
      "0.0174269638956 these pretzels are making me thirsty\n"
     ]
    }
   ],
   "source": [
    "train(srnn, \"these pretzels are making me thirsty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
